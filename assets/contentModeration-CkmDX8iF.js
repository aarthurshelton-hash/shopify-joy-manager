const n="import { supabase } from '@/integrations/supabase/client';\nimport { flagContent, checkUserBanStatus } from './flagContent';\n\ninterface ModerationResult {\n  safe: boolean;\n  reason?: string;\n  flagged?: boolean; // Content was flagged for admin review\n}\n\n/**\n * Check if the current user is banned before allowing content submission\n */\nexport async function checkBanBeforeAction(userId: string): Promise<{ allowed: boolean; reason?: string }> {\n  const banStatus = await checkUserBanStatus(userId);\n  if (banStatus.isBanned) {\n    const expiryText = banStatus.expiresAt \n      ? `Your ban expires on ${new Date(banStatus.expiresAt).toLocaleDateString()}.` \n      : 'This is a permanent ban.';\n    return { \n      allowed: false, \n      reason: `Your account has been suspended. Reason: ${banStatus.reason}. ${expiryText}` \n    };\n  }\n  return { allowed: true };\n}\n\n/**\n * Moderate text content for inappropriate language\n * Also flags suspicious content for admin review\n */\nexport async function moderateText(\n  text: string, \n  options?: { \n    userId?: string; \n    contentType?: string;\n    contentId?: string;\n  }\n): Promise<ModerationResult> {\n  if (!text || text.trim().length === 0) {\n    return { safe: true };\n  }\n\n  // Check if user is banned first\n  if (options?.userId) {\n    const banCheck = await checkBanBeforeAction(options.userId);\n    if (!banCheck.allowed) {\n      return { safe: false, reason: banCheck.reason };\n    }\n  }\n\n  try {\n    const { data, error } = await supabase.functions.invoke('moderate-content', {\n      body: { type: 'text', content: text },\n    });\n\n    if (error) {\n      console.error('Text moderation error:', error);\n      // Fail open - allow if moderation fails\n      return { safe: true };\n    }\n\n    // If content is flagged as unsafe, record it for admin review\n    if (!data.safe && options?.userId && options?.contentType) {\n      await flagContent(\n        options.contentType,\n        options.userId,\n        data.reason || 'Detected inappropriate content',\n        {\n          contentId: options.contentId,\n          contentText: text,\n          severity: 'medium',\n        }\n      );\n    }\n\n    return {\n      safe: data.safe,\n      reason: data.reason,\n      flagged: !data.safe,\n    };\n  } catch (error) {\n    console.error('Text moderation error:', error);\n    return { safe: true };\n  }\n}\n\n/**\n * Moderate image content for inappropriate imagery\n * Also flags suspicious content for admin review\n */\nexport async function moderateImage(\n  imageBase64: string,\n  options?: {\n    userId?: string;\n    contentType?: string;\n    contentId?: string;\n    imageUrl?: string;\n  }\n): Promise<ModerationResult> {\n  if (!imageBase64) {\n    return { safe: false, reason: 'No image provided' };\n  }\n\n  // Check if user is banned first\n  if (options?.userId) {\n    const banCheck = await checkBanBeforeAction(options.userId);\n    if (!banCheck.allowed) {\n      return { safe: false, reason: banCheck.reason };\n    }\n  }\n\n  try {\n    const { data, error } = await supabase.functions.invoke('moderate-content', {\n      body: { type: 'image', content: imageBase64 },\n    });\n\n    if (error) {\n      console.error('Image moderation error:', error);\n      // Fail open - allow if moderation fails\n      return { safe: true };\n    }\n\n    // If content is flagged as unsafe, record it for admin review\n    if (!data.safe && options?.userId && options?.contentType) {\n      await flagContent(\n        options.contentType,\n        options.userId,\n        data.reason || 'Detected inappropriate image',\n        {\n          contentId: options.contentId,\n          contentImageUrl: options.imageUrl,\n          severity: 'high',\n        }\n      );\n    }\n\n    return {\n      safe: data.safe,\n      reason: data.reason,\n      flagged: !data.safe,\n    };\n  } catch (error) {\n    console.error('Image moderation error:', error);\n    return { safe: true };\n  }\n}\n\n/**\n * Convert a File to base64 string for moderation\n */\nexport function fileToBase64(file: File): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onload = () => {\n      const result = reader.result as string;\n      resolve(result);\n    };\n    reader.onerror = reject;\n    reader.readAsDataURL(file);\n  });\n}\n\n/**\n * Client-side quick check for obviously inappropriate text\n * Use as a fast pre-filter before server-side moderation\n */\nexport function quickTextCheck(text: string): { safe: boolean; reason?: string } {\n  if (!text || text.trim().length === 0) {\n    return { safe: true };\n  }\n\n  // Very basic patterns for instant rejection\n  const obviousPatterns = [\n    /\\b(fuck|shit|cunt|nigger|faggot)\\b/gi,\n  ];\n\n  const normalized = text.toLowerCase();\n  \n  for (const pattern of obviousPatterns) {\n    if (pattern.test(normalized)) {\n      return { \n        safe: false, \n        reason: 'Content contains inappropriate language' \n      };\n    }\n  }\n\n  return { safe: true };\n}\n";export{n as default};
