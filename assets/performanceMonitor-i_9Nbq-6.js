const n="/**\n * Performance Monitoring Utilities\n * \n * Tracks Core Web Vitals and custom performance metrics\n * for the En Pensent application.\n * \n * @module performanceMonitor\n */\n\nimport { reportError } from '@/lib/errorReporting';\n\ninterface PerformanceMetric {\n  name: string;\n  value: number;\n  rating: 'good' | 'needs-improvement' | 'poor';\n  timestamp: number;\n}\n\ninterface WebVitalMetric {\n  name: 'CLS' | 'FID' | 'FCP' | 'LCP' | 'TTFB' | 'INP';\n  value: number;\n  id: string;\n}\n\nconst RATING_THRESHOLDS = {\n  LCP: { good: 2500, poor: 4000 },\n  FID: { good: 100, poor: 300 },\n  CLS: { good: 0.1, poor: 0.25 },\n  FCP: { good: 1800, poor: 3000 },\n  TTFB: { good: 800, poor: 1800 },\n  INP: { good: 200, poor: 500 },\n};\n\n/**\n * Get rating based on metric thresholds\n */\nfunction getRating(\n  metricName: keyof typeof RATING_THRESHOLDS,\n  value: number\n): PerformanceMetric['rating'] {\n  const thresholds = RATING_THRESHOLDS[metricName];\n  if (!thresholds) return 'good';\n  \n  if (value <= thresholds.good) return 'good';\n  if (value <= thresholds.poor) return 'needs-improvement';\n  return 'poor';\n}\n\n/**\n * Report Core Web Vital to analytics\n */\nfunction reportWebVital(metric: WebVitalMetric): void {\n  const rating = getRating(metric.name, metric.value);\n  \n  // Log to console in development\n  if (import.meta.env.DEV) {\n    console.log(`[Web Vitals] ${metric.name}: ${metric.value} (${rating})`);\n  }\n  \n  // Send to analytics in production\n  if (import.meta.env.PROD) {\n    // Use sendBeacon for reliability\n    const payload = JSON.stringify({\n      metric: metric.name,\n      value: metric.value,\n      rating,\n      id: metric.id,\n      timestamp: Date.now(),\n    });\n    \n    navigator.sendBeacon?.('/api/analytics/vitals', payload);\n  }\n  \n  // Report poor metrics as errors\n  if (rating === 'poor') {\n    reportError(`Poor ${metric.name}: ${metric.value}ms`, {\n      errorType: 'performance',\n      metadata: { metric: metric.name, value: metric.value },\n    });\n  }\n}\n\n/**\n * Measure and report Largest Contentful Paint (LCP)\n */\nexport function measureLCP(): void {\n  if (!('PerformanceObserver' in window)) return;\n  \n  const observer = new PerformanceObserver((entryList) => {\n    const entries = entryList.getEntries();\n    const lastEntry = entries[entries.length - 1] as PerformanceEntry & { element?: Element };\n    \n    reportWebVital({\n      name: 'LCP',\n      value: lastEntry.startTime,\n      id: lastEntry.entryType,\n    });\n  });\n  \n  observer.observe({ entryTypes: ['largest-contentful-paint'] });\n}\n\n/**\n * Measure and report First Input Delay (FID)\n */\nexport function measureFID(): void {\n  if (!('PerformanceObserver' in window)) return;\n  \n  const observer = new PerformanceObserver((entryList) => {\n    const entries = entryList.getEntries();\n    \n    entries.forEach((entry) => {\n      const fidEntry = entry as PerformanceEntry & { processingStart: number };\n      const delay = fidEntry.processingStart - fidEntry.startTime;\n      \n      reportWebVital({\n        name: 'FID',\n        value: delay,\n        id: entry.entryType,\n      });\n    });\n  });\n  \n  observer.observe({ entryTypes: ['first-input'] });\n}\n\n/**\n * Measure and report Cumulative Layout Shift (CLS)\n */\nexport function measureCLS(): void {\n  if (!('PerformanceObserver' in window)) return;\n  \n  let clsValue = 0;\n  const clsEntries: PerformanceEntry[] = [];\n  \n  const observer = new PerformanceObserver((entryList) => {\n    const entries = entryList.getEntries() as (PerformanceEntry & { value: number; hadRecentInput: boolean })[];\n    \n    entries.forEach((entry) => {\n      if (!entry.hadRecentInput) {\n        clsValue += entry.value;\n        clsEntries.push(entry);\n      }\n    });\n  });\n  \n  observer.observe({ entryTypes: ['layout-shift'] });\n  \n  // Report CLS when page is hidden\n  document.addEventListener('visibilitychange', () => {\n    if (document.visibilityState === 'hidden' && clsEntries.length > 0) {\n      reportWebVital({\n        name: 'CLS',\n        value: clsValue,\n        id: 'cls-final',\n      });\n    }\n  });\n}\n\n/**\n * Measure and report First Contentful Paint (FCP)\n */\nexport function measureFCP(): void {\n  if (!('PerformanceObserver' in window)) return;\n  \n  const observer = new PerformanceObserver((entryList) => {\n    const entries = entryList.getEntries();\n    const fcpEntry = entries[0];\n    \n    if (fcpEntry) {\n      reportWebVital({\n        name: 'FCP',\n        value: fcpEntry.startTime,\n        id: fcpEntry.entryType,\n      });\n    }\n  });\n  \n  observer.observe({ entryTypes: ['paint'] });\n}\n\n/**\n * Measure and report Time to First Byte (TTFB)\n */\nexport function measureTTFB(): void {\n  const navigation = performance.getEntriesByType('navigation')[0] as PerformanceNavigationTiming | undefined;\n  \n  if (navigation) {\n    const ttfb = navigation.responseStart - navigation.startTime;\n    \n    reportWebVital({\n      name: 'TTFB',\n      value: ttfb,\n      id: 'navigation',\n    });\n  }\n}\n\n/**\n * Initialize all Core Web Vitals monitoring\n */\nexport function initializePerformanceMonitoring(): void {\n  // Wait for page to be interactive\n  if (document.readyState === 'complete') {\n    initMetrics();\n  } else {\n    window.addEventListener('load', initMetrics);\n  }\n}\n\nfunction initMetrics(): void {\n  measureLCP();\n  measureFID();\n  measureCLS();\n  measureFCP();\n  measureTTFB();\n  \n  console.log('[Performance] Core Web Vitals monitoring initialized');\n}\n\n/**\n * Measure custom component render time\n * \n * @param {string} componentName Name of the component\n * @param {() => T} fn Function to measure\n * @returns {T} Result of the function\n * \n * @example\n * ```typescript\n * const data = measureComponentRender('UserProfile', () => {\n *   return fetchUserData();\n * });\n * ```\n */\nexport function measureComponentRender<T>(componentName: string, fn: () => T): T {\n  const start = performance.now();\n  const result = fn();\n  const end = performance.now();\n  const duration = end - start;\n  \n  // Report slow renders\n  if (duration > 100) {\n    console.warn(`[Performance] Slow render: ${componentName} took ${duration.toFixed(2)}ms`);\n    \n    if (duration > 500) {\n      reportError(`Very slow component render: ${componentName}`, {\n        errorType: 'performance',\n        metadata: { component: componentName, duration },\n      });\n    }\n  }\n  \n  return result;\n}\n\n/**\n * Mark performance milestones\n * \n * @param {string} label Label for the mark\n */\nexport function mark(label: string): void {\n  if (typeof performance !== 'undefined' && performance.mark) {\n    performance.mark(label);\n  }\n}\n\n/**\n * Measure time between two marks\n * \n * @param {string} name Name for the measurement\n * @param {string} startMark Starting mark label\n * @param {string} endMark Ending mark label\n */\nexport function measure(name: string, startMark: string, endMark: string): void {\n  if (typeof performance !== 'undefined' && performance.measure) {\n    try {\n      performance.measure(name, startMark, endMark);\n      \n      const entries = performance.getEntriesByName(name);\n      const lastEntry = entries[entries.length - 1] as PerformanceEntry & { duration: number };\n      \n      if (lastEntry && lastEntry.duration > 1000) {\n        console.warn(`[Performance] Long operation: ${name} took ${lastEntry.duration.toFixed(2)}ms`);\n      }\n    } catch (e) {\n      // Ignore measurement errors\n    }\n  }\n}\n";export{n as default};
