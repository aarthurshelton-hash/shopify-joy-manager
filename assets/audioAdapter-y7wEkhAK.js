const n="/**\n * Audio/Music Domain Adapter\n * Converts sound waves to En Pensent temporal signatures\n * \n * Music and sound carry temporal patterns that resonate\n * with human emotion and market psychology.\n * This adapter extracts temporal patterns from:\n * - Frequency spectrum analysis\n * - Rhythm and tempo patterns\n * - Harmonic relationships\n * - Dynamic range\n */\n\nimport type { DomainAdapter, UniversalSignal, DomainSignature } from '../types';\n\ninterface AudioData {\n  fundamentalHz: number; // Fundamental frequency\n  amplitude: number; // 0-1 normalized\n  spectralCentroid: number; // \"Brightness\" of sound\n  tempo: number; // BPM\n  key: number; // Musical key (0-11 for C to B)\n  mode: 'major' | 'minor' | 'neutral';\n  timestamp: number;\n}\n\nclass AudioDomainAdapter implements DomainAdapter<AudioData> {\n  domain = 'audio' as const;\n  name = 'Audio Pattern Analyzer';\n  isActive = false;\n  lastUpdate = 0;\n  \n  private signalBuffer: UniversalSignal[] = [];\n  private readonly BUFFER_SIZE = 1000;\n  \n  // Musical frequency references\n  private readonly A4 = 440; // Hz\n  \n  // Tempo classifications\n  private readonly TEMPO = {\n    largo: { min: 40, max: 60 },\n    adagio: { min: 60, max: 80 },\n    andante: { min: 80, max: 100 },\n    moderato: { min: 100, max: 120 },\n    allegro: { min: 120, max: 160 },\n    presto: { min: 160, max: 200 },\n  };\n\n  async initialize(): Promise<void> {\n    this.isActive = true;\n    this.lastUpdate = Date.now();\n    console.log('[AudioAdapter] Initialized - Audio pattern recognition active');\n  }\n\n  processRawData(data: AudioData): UniversalSignal {\n    const { fundamentalHz, amplitude, spectralCentroid, tempo, key, mode, timestamp } = data;\n    \n    // Frequency as base oscillation\n    const frequency = fundamentalHz;\n    \n    // Amplitude as intensity\n    const intensity = amplitude;\n    \n    // Musical key affects phase (emotional resonance)\n    const phase = (key / 12) * Math.PI * 2;\n    \n    // Extract harmonics from audio characteristics\n    const harmonics = this.extractHarmonics(fundamentalHz, spectralCentroid, tempo, key, mode);\n    \n    const signal: UniversalSignal = {\n      domain: 'audio',\n      timestamp,\n      intensity,\n      frequency,\n      phase,\n      harmonics,\n      rawData: [fundamentalHz, amplitude, spectralCentroid, tempo, key, mode === 'major' ? 1 : mode === 'minor' ? -1 : 0],\n    };\n    \n    this.signalBuffer.push(signal);\n    if (this.signalBuffer.length > this.BUFFER_SIZE) {\n      this.signalBuffer.shift();\n    }\n    \n    this.lastUpdate = timestamp;\n    return signal;\n  }\n\n  extractSignature(signals: UniversalSignal[]): DomainSignature {\n    if (signals.length === 0) {\n      return this.getDefaultSignature();\n    }\n\n    const recentSignals = signals.slice(-100);\n    \n    // Calculate quadrant profile from audio characteristics\n    const quadrantProfile = this.calculateQuadrantFromAudio(recentSignals);\n    \n    // Temporal flow from dynamic patterns\n    const temporalFlow = this.calculateTemporalFlow(recentSignals);\n    \n    // Calculate advanced metrics\n    const avgIntensity = recentSignals.reduce((sum, s) => sum + s.intensity, 0) / recentSignals.length;\n    const intensityVariance = this.calculateVariance(recentSignals.map(s => s.intensity));\n    const dominantFreq = this.findDominantFrequency(recentSignals);\n    const harmonicRes = this.calculateHarmonicResonance(recentSignals);\n    const musicalCoherence = this.calculateMusicalCoherence(recentSignals);\n    \n    return {\n      domain: 'audio',\n      quadrantProfile,\n      temporalFlow,\n      intensity: avgIntensity,\n      momentum: this.calculateMomentum(recentSignals),\n      volatility: Math.sqrt(intensityVariance),\n      dominantFrequency: dominantFreq,\n      harmonicResonance: harmonicRes,\n      phaseAlignment: musicalCoherence,\n      extractedAt: Date.now(),\n    };\n  }\n\n  private extractHarmonics(fundamental: number, centroid: number, tempo: number, key: number, mode: 'major' | 'minor' | 'neutral'): number[] {\n    // Create harmonic series from fundamental\n    const modeMultiplier = mode === 'major' ? 1.2 : mode === 'minor' ? 0.8 : 1;\n    const tempoNorm = tempo / 120;\n    const keyNorm = key / 12;\n    \n    return [\n      fundamental / 1000,\n      (fundamental * 2) / 1000 * modeMultiplier,\n      (fundamental * 3) / 1000,\n      (fundamental * 4) / 1000 * modeMultiplier,\n      centroid / 5000,\n      tempoNorm,\n      keyNorm,\n      Math.sin(keyNorm * Math.PI * 2) * modeMultiplier,\n    ];\n  }\n\n  private calculateQuadrantFromAudio(signals: UniversalSignal[]): DomainSignature['quadrantProfile'] {\n    // Map audio characteristics to quadrants\n    // High tempo = aggressive (energy)\n    // Low spectral centroid = defensive (warm, grounded)\n    // High amplitude variation = tactical (dynamic)\n    // Strong harmonic coherence = strategic (structured)\n    \n    const avgTempo = signals.reduce((sum, s) => sum + s.rawData[3], 0) / signals.length;\n    const avgCentroid = signals.reduce((sum, s) => sum + s.rawData[2], 0) / signals.length;\n    const ampVariation = this.calculateVariance(signals.map(s => s.intensity));\n    const modeSum = signals.reduce((sum, s) => sum + s.rawData[5], 0);\n    \n    // Normalize\n    const tempoScore = Math.min((avgTempo - 60) / 140, 1); // 60-200 BPM\n    const warmthScore = 1 - Math.min(avgCentroid / 5000, 1);\n    const dynamicScore = Math.min(ampVariation * 4, 1);\n    const structureScore = Math.abs(modeSum / signals.length);\n    \n    const total = tempoScore + warmthScore + dynamicScore + structureScore || 1;\n    \n    return {\n      aggressive: tempoScore / total,\n      defensive: warmthScore / total,\n      tactical: dynamicScore / total,\n      strategic: structureScore / total,\n    };\n  }\n\n  private calculateTemporalFlow(signals: UniversalSignal[]): DomainSignature['temporalFlow'] {\n    const len = signals.length;\n    const third = Math.floor(len / 3);\n    \n    const earlyEnergy = signals.slice(0, third).reduce((sum, s) => sum + s.intensity * s.frequency, 0) / third || 0;\n    const midEnergy = signals.slice(third, 2 * third).reduce((sum, s) => sum + s.intensity * s.frequency, 0) / third || 0;\n    const lateEnergy = signals.slice(2 * third).reduce((sum, s) => sum + s.intensity * s.frequency, 0) / third || 0;\n    \n    const total = earlyEnergy + midEnergy + lateEnergy || 1;\n    \n    return {\n      early: earlyEnergy / total,\n      mid: midEnergy / total,\n      late: lateEnergy / total,\n    };\n  }\n\n  private calculateVariance(values: number[]): number {\n    if (values.length === 0) return 0;\n    const mean = values.reduce((a, b) => a + b, 0) / values.length;\n    return values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;\n  }\n\n  private calculateMusicalCoherence(signals: UniversalSignal[]): number {\n    // Measure how consistent the musical key and mode are\n    if (signals.length < 2) return 0.5;\n    \n    let coherenceSum = 0;\n    for (let i = 1; i < signals.length; i++) {\n      const keyDiff = Math.abs(signals[i].rawData[4] - signals[i - 1].rawData[4]);\n      const modeDiff = Math.abs(signals[i].rawData[5] - signals[i - 1].rawData[5]);\n      \n      // Closer keys = more coherence\n      const keyCoherence = 1 - (keyDiff / 6); // 6 semitones = max difference\n      const modeCoherence = 1 - (modeDiff / 2);\n      \n      coherenceSum += (keyCoherence + modeCoherence) / 2;\n    }\n    \n    return coherenceSum / (signals.length - 1);\n  }\n\n  private findDominantFrequency(signals: UniversalSignal[]): number {\n    const freqBuckets = new Map<number, number>();\n    \n    signals.forEach(s => {\n      // Bucket by octave\n      const octave = Math.floor(Math.log2(s.frequency / 27.5));\n      const bucket = 27.5 * Math.pow(2, octave);\n      freqBuckets.set(bucket, (freqBuckets.get(bucket) || 0) + s.intensity);\n    });\n    \n    let maxBucket = 440;\n    let maxValue = 0;\n    freqBuckets.forEach((value, bucket) => {\n      if (value > maxValue) {\n        maxValue = value;\n        maxBucket = bucket;\n      }\n    });\n    \n    return maxBucket;\n  }\n\n  private calculateHarmonicResonance(signals: UniversalSignal[]): number {\n    if (signals.length < 2) return 0;\n    \n    let resonanceSum = 0;\n    for (let i = 1; i < signals.length; i++) {\n      const h1 = signals[i].harmonics;\n      const h2 = signals[i - 1].harmonics;\n      \n      let dotProduct = 0;\n      let mag1 = 0;\n      let mag2 = 0;\n      \n      for (let j = 0; j < h1.length; j++) {\n        dotProduct += h1[j] * h2[j];\n        mag1 += h1[j] * h1[j];\n        mag2 += h2[j] * h2[j];\n      }\n      \n      const denom = Math.sqrt(mag1) * Math.sqrt(mag2);\n      const cosineSim = denom > 0 ? dotProduct / denom : 0;\n      resonanceSum += (cosineSim + 1) / 2;\n    }\n    \n    return resonanceSum / (signals.length - 1);\n  }\n\n  private calculateMomentum(signals: UniversalSignal[]): number {\n    if (signals.length < 10) return 0;\n    \n    const recent = signals.slice(-10);\n    const older = signals.slice(-20, -10);\n    \n    const recentEnergy = recent.reduce((sum, s) => sum + s.intensity * s.frequency, 0) / recent.length;\n    const olderEnergy = older.length > 0 \n      ? older.reduce((sum, s) => sum + s.intensity * s.frequency, 0) / older.length \n      : recentEnergy;\n    \n    return (recentEnergy - olderEnergy) / (olderEnergy || 1);\n  }\n\n  private getDefaultSignature(): DomainSignature {\n    return {\n      domain: 'audio',\n      quadrantProfile: { aggressive: 0.25, defensive: 0.25, tactical: 0.25, strategic: 0.25 },\n      temporalFlow: { early: 0.33, mid: 0.34, late: 0.33 },\n      intensity: 0.5,\n      momentum: 0,\n      volatility: 0,\n      dominantFrequency: 440,\n      harmonicResonance: 0.5,\n      phaseAlignment: 0.5,\n      extractedAt: Date.now(),\n    };\n  }\n\n  // Generate audio signal correlated with market mood\n  generateMarketCorrelatedSignal(marketMomentum: number, marketVolatility: number): AudioData {\n    // Market momentum affects musical mode and tempo\n    const mode: 'major' | 'minor' | 'neutral' = \n      marketMomentum > 0.2 ? 'major' : \n      marketMomentum < -0.2 ? 'minor' : 'neutral';\n    \n    // Volatility affects tempo (higher volatility = faster tempo)\n    const tempo = 80 + (marketVolatility * 80);\n    \n    // Momentum affects fundamental frequency (bullish = higher pitch)\n    const fundamentalHz = 220 + (marketMomentum * 220);\n    \n    // Volatility affects amplitude (uncertainty = louder)\n    const amplitude = 0.4 + (marketVolatility * 0.5);\n    \n    // Spectral centroid rises with excitement\n    const spectralCentroid = 2000 + (marketVolatility * 2000) + (Math.abs(marketMomentum) * 500);\n    \n    // Key selection based on momentum direction\n    // C major (0) for positive, A minor (9) for negative\n    const key = marketMomentum >= 0 ? 0 : 9;\n    \n    return {\n      fundamentalHz: Math.max(55, Math.min(880, fundamentalHz)),\n      amplitude: Math.max(0, Math.min(1, amplitude)),\n      spectralCentroid: Math.max(500, Math.min(8000, spectralCentroid)),\n      tempo: Math.max(40, Math.min(200, tempo)),\n      key,\n      mode,\n      timestamp: Date.now(),\n    };\n  }\n}\n\nexport const audioAdapter = new AudioDomainAdapter();\nexport type { AudioData };\n";export{n as default};
